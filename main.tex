\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}

\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}

\begin{document}

\title{OUXT Polaris: Autonomous Navigation System for the 2022 Maritime RobotX Challenge}
\author{
    Kenta Okamoto,Kyoto Institute of Tech., m2623106@edu.kit.ac.jp \\ \and
    Akihisa Nagata, Kansai Univ. , k065604@kansai-u.ac.jp \\ \and
    Kyoma Arai, Tokai Univ. , 2cemm007@mail.u-tokai.ac.jp \\ \and
    Masato Kobayashi, Kobe Univ. , 171w951w@gsuite.kobe-u.ac.jp \\ \and
    Yusei Nagao, Osaka Institute of Tech., m1m22r23@oit.ac.jp \\ \and
    Yuki Nishimura, Osaka Univ., hbvcg00@gmail.com \\ \and
    Shunya Tanaka, , syun111@gmail.com \\ \and
    Masaya Kataoka, TIER IV inc . , ms.kataoka@gmail.com,
}

% The paper headers
\markboth{Maritime RobotX Challenge 2022}%
{Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}

% \IEEEpubid{0000-0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\begin{abstract}
OUXT-Polaris has been developing an autonomous navigation system by participating in the 
Maritime RobotX Challenge 2014, 2016, and 2018. 
In this paper, we describe the improvement of the previous vessel system. 
We also indicate the advantage of the improved design.
Moreover, we describe the developing method for Covid-19 and the 
feature components for the next RobotX Challenge.
\end{abstract}

\begin{IEEEkeywords}
Maritime systems, Robotics, Unmanned surface vehicle
\end{IEEEkeywords}

\section{Introduction}
First of all, we are motivated to develop a big field robot in a large area such as the ocean.
In recent years, the aging and shrinking population, as well as a shortage of workers,
has led to an increase in demand for the automation of cars, robots, and other equipment.
Among these, automated driving is being developed with particular emphasis.
Moving the autonomous vehicle or robot outside has a very severe problem.
They need to hedge unknown obstacles and go to the target position.
The environment such as weather, temperature, or underwater around robots causes sensor and hardware problems.
There are each challenging problems and They are also interesting for us, and there are different problems between land and ocean.
On the land, the navigation or the estimation of the self-position is solved by the point cloud map and the odmetry,
while on the ocean, the point cloud and the odmetry is not obtained enough. So the robots need to estimate the self-position using GPS and IMU sensors.
Moreover, on the land, the position of the target objects and obstacles is obtained from Lidar data. On the other hand in the sea,
waves disturbe to get the target positions. In that case, the robots have to fusion multiple data such as cameras and Lidars.
In this competition, we have a chance to develop a system to get over the wild environment 
for the robots on the ocean. Therefore, we are participating in the Maritime RobotX Challenge.

\section{Overview of vessel system}
First, we describe the architecture of the navigation system. As you can see \ref{fig:arch_nav},
the position and the velocity of WAM-V are estimated using the Extended Kalman Filter from the data of the GNSS and IMU sensors.
The obstacles and task objects are recognized from lidar and camera data. Based on the self-position and the task objects, 
WAM-V decides where to go and what to do next.
After getting the target position, the path is created by the path planner,
and the target velocity that WAM-V can trace the way is calculated. 
Finally, in the servo and thruster controllers,
the servo motor direction and the thruster revolution to achieve the target velocity are calculated based on the vessel motion model.

\section{Hardware Developments}

\subsection{MINI-V in the COVID-19}
MINI-V(minitua vessel) was created in order to test the software easily in the Covid-19. Over the past several years, 
we couldn't conduct the experiment on the ocean or lake because of the COVID-19.
We were prohibited to meet and create the parts of WAM-V.
In addition, the law about vessels is very strict.
So, we can't float the boat easily. The WAM-V is so big and it is hard work and costs too much to carry WAM-V to the lake. 
Then, we need a sustainable system to develop the automotive vessel.
As mentioned above, the simulator is used for developing navigation systems, and it doesn't need to use WAM-V.
The perception array was created to get the sensor data for software tests. They made it easier for us to develop software without ships.
However, the software and hardware integration is the most important to conduct tasks. Then, MINI-V was created 
to make it easier to do the test and the integration.

The concepts of MINI-V are follows:
\begin{enumerate}
  \item easy assembly, transport, and experiment,
  \item open source software and hardware,
  \item high compatibility between WAM-V and MINI-V.
\end{enumerate}

\begin{figure}[h]
  \begin{center}
    \scalebox{0.24}{
      \includegraphics{figure/arch_nav.eps}
    }
  \end{center}
  \caption{the archtecture of navigation system}
  \label{fig:arch_nav}
\end{figure}


\begin{figure}[h]
    \begin{center}
      \scalebox{0.24}{
      \includegraphics{figure/mini_v_component.png}
    }
  \end{center}
  \caption{Hardware components of MINI-V}
  \label{fig:mini_v_component}
\end{figure}

\begin{figure}[h]
    \begin{center}
      \scalebox{0.24}{
        \includegraphics{figure/mini_v_overview.png}
      }
    \end{center}
    \caption{Experiment on the Ai river}
    \label{fig:mini_v_experiment}
  \end{figure}

MINI-V is created to be easy to carry, and we can carry them by suitcase like Fig. \ref{fig:mini_v_component}.
It is also assembled simply. We develop this vessel on open source. So, other people can play or test their software with MINI-V. Finally,
we expect the high compatibility between WAM-V and MINI-V, and it will make it easy to migrate developed software on MINI-V toWAM-V. However, 
MINI-V have not had complete compatibility yet.
We have future tasks to create a little bigger vessel to have compatible hardware and software such as batteries and sensors, and so on.

\section{Software Developments}
\subsection{ROS2-based Autonomous Navigation Stack}
In “Maritime RobotX Challenge 2018”, we used Robot Operating System 1(ROS1) for developing software.
However, the development of ROS1 was finished with python2 end of life.
Therefore, we adopted the next generation of ROS called “ROS2”.
As shown in Fig. 1, our ROS2-based simulation and software system was already developed.
Our software contributions are listed as follows.

\begin{itemize}
  \item {\it Software System }:
    We rebuilt the software system from ROS1 to ROS2
  \item {\it Behavior Tree}:
    We adopted the behavior tree library in ROS2 and built our original behavior tree.
  \item {\it Simulation Tool Development }:
    We developed LiDAR simulation by using intel ray-tracing OSS "Embree".
  \item {\it CI/CD}:
    CI/CD systems are developed on the GitHub Actions Platform.
  \item {\it Object Detection}:
    We are developing a lidar-camera fusion object detection system for this project.
\end{itemize}
We published all codes in GitHub to give feedback knowledge to the ROS community and 
Open-Source all our resources not only software but also including CAD models, and circuit data.

\subsection{Software System Architecture}
Our navigation stack is based on ROS2, but we do not use the navigation2 library. We develop our original software.
Our software is highly modularized, so some of our members use our stacks in other autonomous mobility competitions.

\subsection{Object Detection}
We used  YOLOX\cite{YOLOX} for object Detection of task object information such as buoys and docks.
We created annotation data based on images and videos obtained from past RobotX Challenges.
The result of training and inference is shown in Fig. hoge. 
The image is part of a video recorded during our challenging navigation in the 2018 RobotX Challenge.\cite{{RobotX2018_video}}

\section{Conclusion}
In this paper, OUXT-Polaris reported the development of the autonomous navigation system for the 2022 RobotX Challenge.
Based on the results of the 2018 RobotX Challenge, OUXT-Polaris rebuilt the system and
developed improved systems for the Maritime RobotX Challenge 2022.
We succeeded in constructing the highly reusable system by designing systems with high independence as parts,
in addition to high computing capacity and environmental recognition capability.
Moreover, we described the developing method in Covid-19 and the feature components for the next RobotX Challenge.
We hope these significant upgrades will produce positive results in the next competition.

% \section*{Acknowledgments}
\begin{thebibliography}{1}
\bibliographystyle{IEEEtran}

  \bibitem{YOLOX}
  Ge, Zheng, et al. "Yolox: Exceeding yolo series in 2021." arXiv preprint arXiv:2107.08430 (2021).

  \bibitem{RobotX2018_video}
  \url{https://www.youtube.com/watch?v=MqDBxzS4uy4}

\end{thebibliography}

\vfill

\end{document}
